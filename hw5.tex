\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\newcommand{\R}{\mathbb{R}}

\title{Algorithmic Operation Research \\ Homework 5}
\date{9-12-2019}
\author{Theodora Panagea - 1115201400135 \\ Anna-Aikaterini Kavvada - 1115201500050}

\begin{document}
	\maketitle{}
  	\pagenumbering{arabic}
 
 \newpage
%-------------------Exercise 1----------------------------  	
\subsection*{Exercise 1}
\textit{Consider the linear programming problem}

\begin{align*}
\text{min } \qquad &x_1 - x_2 \\
\text{s.t.} \qquad 2&x_1 + 3x_2 -x_3 + x_4 \leqslant 0 \\
						    3&x_1 + x_2 + 4x_3 - 2x_4 \geqslant 3 \\
						    -&x_1 - x_2 +2x_3 + x_4 = 6 \\
						    &x \leqslant 0 \\
						    &x_2, x_3 \geqslant 0
\end{align*}
\\
\textit{Write down the corresponding dual problem.}
\\
\textbf{Solution:} \\  	
\begin{align*}
\text{max } \qquad 3&p_2 + 6p_3 \\
\text{s.t.} \qquad 3&p_1 + p_2 - p_3 \leqslant -1 \\
						    -&p_1 + 4p_2 + 2p_3 \leqslant 0 \\
						    2&p_1 + 3p_2 - p_3 \geqslant 1 \\
						    &p_1 - 2p_2 + 3p_3 = 0 \\
						    &p_1 \leqslant 0 \\
						    &p_2 \geqslant 0 \\
						    &p_3 \quad \text{free}
\end{align*}
  	
  	
\newpage

%-------------------Exercise 2----------------------------  	
\subsection*{Exercise 2}
\textit{Consider the primal problem} \\
\begin{align*}
\text{min } \qquad & c' x \\
\text{s.t. } \qquad  & Ax \geqslant b \\
							& x \geqslant 0
\end{align*}
\textit{Form the dual problem and convert it into an equivalent minimization problem. Derive a set of conditions on the matrix $A$ and the vectors $b,c$ under which the dual is identical to the primal.}
\\
\textbf{Solution:} \\  
Let's consider the dual problem: \\
\begin{align*}
\text{max } \qquad & p' b \\
\text{s.t. } \qquad  & p'A \leqslant c \\
							& p \geqslant 0
\end{align*}
Then we will convert it to equivalent minimization, manipulating the constraint to mirror the format of the primal: 
\begin{align*}
\text{min } \qquad  -&p' b \\
\text{s.t. } \qquad  -&p'A \geqslant -c' \\
							& p \geqslant 0
\end{align*}
\\
Firstly, we must have $A$ be a $n \times n$ matrix, in order to make the dual problem of same dimension. This implies that $-p'A \geqslant -c' \Leftrightarrow -A'p \geqslant -c$, so for this to be the same problem, we need $b = -c$ (which also guarantees $-p'b = c'x$) and $A = -A'$, which means that $A$ is skew-symmetric. We have to note that $p$ and $x$ both have the same nonnegativity constraints, and therefore, these problems are equivalent.


\newpage

%-------------------Exercise 3----------------------------  	
\subsection*{Exercise 3}
\textit{The purpose of this exercise is to show that solving linear programming problems is no harder than solving systems of linear inequalities. Suppose that we are given a subroutine which, given a system of linear inequalities either produces a solution or decides that no solution exists. Construct a simple algorithm that uses a single call to this subroutine and which finds an optimal solution to any linear programming problem that has an optimal solution. }
\\
\textbf{Solution:} \\  
Let's consider  the primal problem: 
\begin{align*}
\text{min } \qquad & c' x \\
\text{s.t. } \qquad  & Ax \geqslant b \\
							& x \geqslant 0
\end{align*}
Then, the dual problem will be the following: 
\begin{align*}
\text{max } \qquad & p' b \\
\text{s.t. } \qquad  & p'A \leqslant c \\
							& p \geqslant 0
\end{align*}
From strong duality, we know that $c'x \geqslant p'b$, for feasible $x,p$. \\
If $c'x = p'b$, then $x,p$ are optimal for the primal and dual problem respectively. Thus, we create the following system:
\begin{align}
Ax &= b \\
x &\geqslant 0 \\
p'A &\leqslant c \\
c'x &= p'b
\end{align} \\
The (1) and (2) are needed for the feasibility of the primal problem. The (3) is for the dual's feasibility and the final equation is for the optimality. \\
Finally, we have to call the subroutine once, with the above system as input.

\newpage

%-------------------Exercise 4----------------------------  	
\subsection*{Exercise 4}
\textit{Let $A$ be a symmetric matrix. Consider the linear program}
\\
\begin{align*}
\text{min } \qquad & c'x \\
\text{s.t. } \qquad  & Ax \geqslant b \\
							& x \geqslant 0
\end{align*}
\textit{Prove that if $x*$ satisfies $A x* = c$ and $x* \geqslant 0$ then $x*$ is an optimal solution.}
\textbf{Solution:} \\  
Let $A$ be a symmetric square matrix. If $x*$ satisfies $Ax* = c$ and $x* \geqslant 0$, then $x*$ is an optimal solution. We form the dual problem of the above, keeping in mind that A is square, and therefore, all dimension will be identical to the primal.
\begin{align*}
\text{max } \qquad & p' c \\
\text{s.t. } \qquad  & p'A \leqslant c \\
							& p \geqslant 0
\end{align*} \\
Let $p* = x* \geqslant 0$. Then, $p *' A$ can be transformed as: $p *' A = A'p* = Ap* = Ax* = c$, because A is symmetric ($A = A'$) and square. So, $p*$ is a feasible solution. Afterwards, we can see that $c'x* = x*'c = p*'c$, so the objective functions of the primal and the dual take on equivalent values for solutions $x*, p*$ respectively. For the aforementioned, we can conclude that $x*$ is an optimal solution.
\newpage

%-------------------Exercise 5----------------------------  	
\subsection*{Exercise 5}
\textit{Write down the proof of complimentary slackness theorem. }
\\ 
\textbf{Solution:} \\  
Primal Problem: \newline
$$min\quad c'x$$ $$s.t. \quad Ax \geq b$$ $$x \geq 0$$
Dual Problem: \newline
$$max \quad p'b$$ $$s.t. \quad p'A = c'$$ $$p \geq 0$$
\textbf{Theorem of Slackness:} \newline
Let $x$ and $p$ be feasible solutions to the primal and the dual problem respectively. They are optimal solutions if and only if:
$$p_i(A'_ix - b_i) = 0$$
$$(c_j - p'A_j)x_j = 0$$

\textbf{\textit{Proof:}}\newline
Given that x, p are feasible solutions to both the primal and dual problem, we have:
$$p'b \leq pAx \leq c'x$$
From Collorary 2 of the Weak Duality Theorem we have that if $x, p$ are feasible, thay are optimal if and only if $$p'b = c'x.$$
For: $(c_j - p'A_j)x_j = 0 \Longrightarrow c_j - p'A_j = 0$\newline
From the above we have: $$\bullet \quad x \geq 0$$ $$\bullet \quad pA < c$$
Thus, we conclude that $cx = pAx$ if and only if for all $i$ either $pA_i = c_i$, with $x_i > 0$ or $x_i = 0$.\newline
Same for: $p_i(A'_ix - b_i) = 0 \Longrightarrow A'_ix - b_i = 0$\newline
where we know that $$pAx = pb$$ if and only if either $a_ix = b$, with $p' >0$ or $p'_i = 0$.
  	
\end{document}